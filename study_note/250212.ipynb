{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastcampus\n",
    "## 성능고도화 기법\n",
    "### 가중치 초기화\n",
    "1. 모델의 층이 깊어질수록 active function 이후 데이터의 분포가 한쪽으로 쏠릴 수 있다.\n",
    "2. 전역 최소값을 나아가는 과정에서 Plateau에 빠졌을 경우 빠르게 빠져 나올 수 있다.\n",
    "3. 모델의 층이 깊어질수록 loss function으로부터의 기울기 값이 점점 작아지거나 커질 수 있다.\n",
    "\n",
    "#### 초기화 방법\n",
    "1. 모두 0으로 초기화 = loss function으로부터의 기울기 값이 업데이트가 되지 않음. = parameter 진행 안됨 = 학습 x\n",
    "2. 모두 균등하게 초기화 = 출력 값의 범위가 넓어져서 안정적인 학습을 기대하기 어려워짐\n",
    "3. 표준 정규분포로 초기화 = 가중치의 값이 너무 크거나 작게 초기화 되어 학습에 저해 가능성 있음\n",
    "4. Xavier 초기화 = \n",
    "- sigmoid 나 Tanh와 같은 Linear activate function 혹은 이들의 근사를 사용할 때 효과적. \n",
    "- 초기에 너무 큰 가중치 값을 설정하면 gradient가 너무 커지거나 작아져서 학습이 어렵게 될 수 있는 문제를 해결할 수 있다. \n",
    "- 또한, 이전 레이어의 노드 수에 비례해 가중치를 초기화한다. 이를 통해 이전 레이어의 노드 수가 많을 수록 각 가중치의 크기는 작아지게 된다.\n",
    "5. He 초기화\n",
    "- 이전 레이어의 노드 수에 비례해 가중치를 초기화\n",
    "- ReLU active function의 특성 때문에 더 큰 스케일을 사용한다. 이는 ReLU active function이 음수일 때 0을 출력하므로, 더 큰 가중치로 시작해 기울기 소실 문제를 완화하는데 도움이 됨.\n",
    "### 가중치 초기화와 배치 초기화의 차이점\n",
    "가중치 초기화도 데이터를 정규화 하고 배치정규화도 활성 후 레이어 이후의 출력을 정규화 한다는 공통점이 있으나 언제 누구에게 사용되느냐에 차이점이 있다.\n",
    "가중치 초기화의 경우 학습시에만 1호성으로 시행되는데 반해, 배치 정규화는 학습 시 지속적으로 추론시도 사용\n",
    "## overfitting 방지\n",
    "### 가중치 감쇠\n",
    "큰 가중치에 대한 패널티를 부과해서 모델의 가중치를 작게 유지하려고 한다. 이를 통해 모델의 복잡도를 감소시켜 모델이 훈련 데이터에 과도하게 적합하는 것을 억제하게 된다. 이는 특히 훈련 데이터가 적거나 노이즈가 많은 경우에 유용하다.\n",
    "### 학습 조기종료\n",
    "학습이 진행될수록 모델의 학습 오차는 게속해서 줄어들어 과적합이되고 검증 오차는 어느순간 증가한다.  \n",
    "= training error는 줄지만 validation은 증가할 경우 학습을 중지하는 방법\n",
    "### 학습 스케쥴러\n",
    "학습률 (Learning rate)를 동적으로 조절하는 역할\n",
    "- Constant\n",
    "- Step Decay\n",
    "- Exponential Decay\n",
    "- Cosine Annearling\n",
    "- One-Cycle Policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 대회에 적용해보기\n",
    "1. 가중치 감쇠는 적용할만한 기술인 듯."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastcampus\n",
    "## Deep Learning\n",
    "### 딥러닝의 발전 1~3\n",
    "#### 딥러닝의 발전 5단계 총괄\n",
    "1. Rule based programing\n",
    "- 규칙 기반 프로그래밍은 목표 달성에 필요한 연산 방법을 사람이 전부 고안.\n",
    "ex. 귀의 길이, 코의 색, 눈의 크기 등의 여러 변수를 모두 설정 및 설계\n",
    "\n",
    "2. conventional machine learning\n",
    "- 특징은 사람이 설계를 하지만(Hand designed feature) 판단하는 logic은(Machine learning) 기계가 함.\n",
    "    - 학습 데이터 준비 (이미지 수집 - 특징(feature) 정의 - 학습 데이터 생성(각 이미지마다의 값 지정))\n",
    "    - 모델 학습 (계산의 결과(예측값)와 정답값과의 오차가 작아지도록 학습 시킴.) (Try & Error 방식)\n",
    "    \n",
    "3. Deep learning\n",
    "- SW2.0 방식\n",
    "- 설계까지 기계에게 맡김. (특징 생성 및 선택까지 기계가 학습)\n",
    "- 자유도가 너무 높아 연산들의 구조를 잡고 사용 (CNN, RNN 등)\n",
    " \n",
    "4. pre-training & Fine-tuning\n",
    "- 기존의 문제점: 분류 대상이/태스크가 바뀔 때마다 다른 모델이 필요해짐. (산업적으로 퍼지는 속도가 느림)\n",
    "- step 1: 사전학습; 많은 동물을 구별하는 일반적인 특징을 익히게 함.\n",
    "- step 2: 미세 조정; 태스크를 수행하기 위해서 맵핑 쪽에 해당하는 연산들만 새로 학습\n",
    "- step 1은 고정하고 step 2만 다시 training 실행\n",
    "\n",
    "5. Big Model & zero/few shot (Text에만 해당)\n",
    "- in context learning; \n",
    "    - task별로 다 다른 모델이 필요한 4단계, \n",
    "    - 5단계에서는 task 별로 별도 모델이 필요가 없음. = task에 맞는 데이터 모을 필요가 없음\n",
    "    - 입력된 문장을 보고 스스로 task를 이해하고 수행함 (GPT_3)\n",
    "    - 특정 크기(175B) 이상의 parameter가 있으면 in context learning이 가능해짐.\n",
    "        - zero shot / one shot/ few shot : 명령 입력시 예시 개수.\n",
    "\n",
    "#### 딥러닝 기술 종류\n",
    "1. data의 종류에 따라 구별\n",
    "2. learning 학습 방법에 따라 구별\n",
    "3. task 해결하는 문제에 따라 구별\n",
    "##### 학습 방식에 의한 구분\n",
    "1. 교사학습\n",
    "- 정답이 필요함(labeling 필수)\n",
    "- 분류 문제와 회귀 문제에 강한 학습(숫자 예측)\n",
    "    - 분류: 기정의된 클래스들 중 입력이 어느 클래스에 해당하는지 맞추는 태스크\n",
    "    - 회귀: 입력 데이터에 대한 실수 혹은 실수의 집합을 출력으로 맵핑해주는 태스크\n",
    "    - 객체검출: 분류 + 회귀 (YOLO)\n",
    "- 라벨링 노이즈: 교사 학습에서 중요한 것은 데이터의 품질이고, 라벨링 노이즈에 따라 교사 학습의 성능이 좌지우지 됨. (학습 데이터가 균형적으로 배치되어 있어야함.)\n",
    "- 라벨링 결과에 대한 노이즈 = 라벨링 작업에 대해 일관되지 않음의 정도\n",
    "\n",
    "2. 비교사 학습\n",
    "- 라벨링 데이터와 피드백이 없음(출력에 대한 정보 제공 안함)\n",
    "- 숨은 구조 찾기를 통해 간접적으로 정답 유추\n",
    "- 클러스터링 / 차원축소 문제에 강점을 가짐\n",
    "    - 클러스터링: 군집화.\n",
    "    1. 임의의 두 점을 정하고 클래스를 부여\n",
    "    2. 나머지 점들은 가장 가까운 쪽의 클래스 중심점의 클래스 부여\n",
    "    3. 클래스별 중심점 재 계산 후 2번 과정 반복\n",
    "\n",
    "    - 차원 축소: N차원 입력을 n차원 출력으로 변경하는 task\n",
    "    1. n 개의 차원벡터 를 차원 확대를 시켰을 때, 입력 값이 나오도록 학습\n",
    "    2. 사용이유: 정보 압축, 정보의 시각화(사람이 볼 수 있는 것은 3차원까지), 정보 특징을 추출하여 분석에 사용\n",
    "\n",
    "3. 강화학습\n",
    "- 라벨링된 데이터 x\n",
    "- 보상신호를 제공해줌(지연 피드백)\n",
    "- 주어진 환경에서 더 높은 보상을 위해서 최적의 행동을 취하는 정책을 학습\n",
    "- agent / reward / action / environment로 구성\n",
    "\n",
    "##### 데이터 형식에 의한 구분\n",
    "1. 정형 데이터\n",
    "- 전통 머신러닝 기법\n",
    "- 구조화된 정보로 저장되어 있는 것. (엑셀로 표현이 가능한가)\n",
    "- 비정형 데이터를 구조화된 데이터로 변경할 수 있다. (ex. Image를 데이터로 바꿀 수 있음)\n",
    "2. 비정형 데이터\n",
    "- 이미지/동영상: 컴퓨터 비전\n",
    "    - 지문인식, 번호판인식, 자율주행, 명함 인식, 영수증 인식, 누끼따기, 스타일 변환 등등...\n",
    "- 텍스트: 자연어 처리\n",
    "    - 문장작성, 혐오글 분류, 번역, 감정 분류 등...\n",
    "    - LLM(Large Language Model)/ ChatGPT 이후 자연어 처리 관련 서비스/제품들이 기하급수적으로 증가. 현재 딥러닝 기술 선두\n",
    "- 음성: 음성인식/생성\n",
    "    -  음성인식, 감정분류, 나이인식, 화자 분류 등...\n",
    "    - TTS or STT \n",
    "##### Task 종류에 의한 구분\n",
    "비정형 데이터와 정보의 입출력 관계에 따라 인식 혹은 생성으로 구분됨\n",
    "1. 인식은 비정형 데이터 입력에 정보가 출력이고, 생성은 출력이 비정형 데이터인 경우에 해당한다.\n",
    "2. 생성은 의도된 정보를 입력으로 넣어줄 수도 있고, 비정형 데이터를 입력으로 주면서 간접적으로 의도를 줄 수도 있다.  \n",
    "\n",
    "이미지 생성: 거의 불가능할 것 같은 이 태스크의 가능성을 보여준 건 2014년의 GAN\n",
    "- 통제력 달성은 결국 입력을 텍스트로 받아서 해결. openAI에서 '21년도에 공개한 DALL-E가 대표적\n",
    "- 23년도에 StabilityAI의 Stable Diffusion이 상업적으로도 이용가능하면서 오픈소스여서 관련 산업이 급격히 성장\n",
    "    - 원하는 이미지가 나오게 하기 위해서는 꽤 상세하게 원하는 그림에 대해서 묘사해야 한다. = prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Learning\n",
    "### 딥러닝 개요\n",
    "#### 딥러닝을 구성하는 필수적인 요소\n",
    "1. Data\n",
    "2. Model\n",
    "3. Loss Function (모델의 결과에 대한 오차를 수치화)\n",
    "4. Optimization Algorithm (loss function의 값이 최소가 되도록 모델의 파라미터를 조정)\n",
    "5. 성능 향상을 위한 기타 알고리즘\n",
    "##### Data\n",
    "해결하고자 하는 문제에 따라 필요로 하는 데이터의 형태나 구성이 달라진다. (labeling 여부)\n",
    "##### Model\n",
    "입력을 원하는 결과로 바꾸어주는 일련의 연산과정을 구조화 한것. (딥러닝의 학습대상)\n",
    "##### Loss function\n",
    "실제 혹은 목표로 하는 값과 모델의 추정값 사이의 차이(=오차)를 수치화하는 함수\n",
    "- ex. RMSE\n",
    "##### Optimization Algorithm\n",
    "손실 함수가 최소값을 가지도록 모델의 파라미터를 최적화하는 알고리즘\n",
    "- parameter = 어떠한 시스템이나 함수의 성질을 나타내는 변수 = 연산을 위해 정해줘야 하는 값 (함수의 계수와 같은 의미)\n",
    "##### 딥러닝 파이프라인\n",
    "모델이 데이터를 통해 추정한 값이 정답/목표와 최대한 가까워지도록(Loss function의 값이 최소가 되도록) 파라미터를 최적화 알고리즘을 적용하여 최적의 모델 파라미터를 찾는 과정\n",
    "### 다층 퍼셉트론\n",
    "#### 뉴럴넷 개요\n",
    "##### 기계가 손글씨 숫자를 인식하는 과정 : 전통방식\n",
    "1. 샘플들을 보면서 패턴을 파악한다.(주요 특징을 뽑아낸다. handcraft Feature)\n",
    "- 숫자 9는 이미지 상반부에는 원이 있고 하반부에는 세로 선이 있음.\n",
    "2. 주요 톡징을 프로그래밍 언어로 표현한다.\n",
    "3. 의사 결정 룰을 정한다.\n",
    "- 숫자 1의 조건이 충족될 경우 1, 아닐 경우 숫자 7의 조건을 확인, 아닐 경우 숫자 0의 조건을...  \n",
    "이전에는 새롭고 좋은 특징을 찾아내면 논문을 낼 수 있었다. 의사 결정 룰은 전통적인 머신러닝의 방식을 사용하기도 한다.\n",
    "\n",
    "#### 퍼셉트론\n",
    "#### 다중 퍼셉트론\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

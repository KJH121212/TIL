{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps란\n",
    "ML Life cycle을 체계적으로 관리하여 더 빠르고 신뢰할 수 있는 결과를 달성하는데 중점\n",
    "\n",
    "## 인프라의 역할\n",
    "적절한 인프라 구성은 데이터 처리 모델 트레이닝, 배포 및 모니터링과 같은 핵심 작업을 지원  \n",
    "이러한 작업들을 원할하고 안정적으로 수행할 수 있게 하는 것이 인프라  \n",
    "\n",
    "### 주요 인프라 요소\n",
    "1. strage\n",
    "- 데이터의 저장, 백업 복구 기능을 제공\n",
    "- 대규모 이미지 데이터 셋을 s3 버킷에 저장하여 머신러닝 모델 트레이닝에 활용\n",
    "2. computing resources\n",
    "- 데이터처리, 분석, 보델 트레이닝에 필요한 컴퓨팅 파워를 제공\n",
    "- Computing Engine 에서 GPU를 활용해 복잡한 머신러닝 모델을 빠르게 트레이닝\n",
    "3. 환경관리 툴\n",
    "- 프로젝트별 독립적인 환경을 제공하는 패키지 및 환경관리 시스템\n",
    "- conda 환경을 사용해 팀 내 다양한 머신러닝 프로젝트의 의존성을 관리리\n",
    "4. container\n",
    "- 애플리케이션과 그 의존성을 패키지화하여 일관된 환경에서 실행할 수 있도록 지원\n",
    "- Docker 컨테이너를 사용해 모델 트레이닝 환경을 일관되게 유지\n",
    "5. orchestrator\n",
    "- 컨테이너를 관리하고 배포 확장, 네트워킹을 관리\n",
    "- Kubernetes를 사용해 여러 모델 서빙 컨테이너를 자동으로 스케일링 및 관리\n",
    "6. workflow Management\n",
    "- 작업을 효율적으로 컴퓨팅 리소스에 할당하고 실행\n",
    "- airflow를 사용해 일일 데이터 처리 및 모델 트레이닝 작업을 자동화  \n",
    "6. CI/CD\n",
    "- 모델 개발 및 테스트 주기를 단축시켜 빠른 반복을 가능하게 하는 도구\n",
    "- 새로운 모델 알고리즘 코드가 업데이트 되면, 자동으로 모델을 학습/평가/검증하여서 프로덕션 환경으로 릴리즈\n",
    "7. version control\n",
    "- 소프트웨어 프로젝트의 다양한 요소를 버전관리리 진행\n",
    "- 이전에 개발된 모델 재현을 위해 원하는 버전의 데이터, 코드를 활용\n",
    "8. http & rest API\n",
    "- 다른 시스템과의 통신을 위한 표준 프로토콜 및 인터페이스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage와 Computing\n",
    "### Storage\n",
    "MLOps에서 데이터를 저장, 관리 검색하는 중요한 구성요소  \n",
    "데이터의 안정성, 접근성, 및 확장성을 보장하는 것이 핵심  \n",
    "\n",
    "중요성\n",
    "1. 데이터 보존\n",
    "2. 접근성\n",
    "3. 확장성\n",
    "\n",
    "유형\n",
    "1. 클라우드 스토리지\n",
    "- ex. Amazon S3, Google Cloud Storage,Azure Blob Storage  \n",
    "기능\n",
    "- 확장성: 거의 무한에 가까운 저장공간제공, 데이터 양에 따라 자유롭게 확장 가능\n",
    "- 내구성과 가용성: 데이터 복제 및 여러 지역에 걸친 분산 저장으로 높은 내구성 및 가용성 보장\n",
    "- 안정성: 고급 암호화 및 보안 프로토콜을 통해 데이터 보호.\n",
    "- 비용 효율성 : 사용한 만큼만 비용지불, 다양한 저장 옵션 제공.\n",
    "\n",
    "2. 분산파일 시스템\n",
    "- ex. Hadoop Distributed File System(HDFS)  \n",
    "기능\n",
    "- 대규모 데이터 처리 : 여러 노드에 걸쳐 대규모 데이터를 분산 저장하고 처리\n",
    "- 고가용성: 데이터를 여러 노드에 복제하여 하나의 노드에 문제가 발생해도 데이터 손실 방지\n",
    "- 확장 가능한 아키텍쳐: 데이터 양이 증가함에 다라 쉽게 노드를 추가하여 시스템 확장 가능.\n",
    "- 비용 효율적: 오픈 소스 솔루션을 사용하여 비용 절감 가능.\n",
    "\n",
    "3. 데이터 웨어하우스\n",
    "- ex. Snowflake, Amazon Redshift, Google BigQuery  \n",
    "기능\n",
    "- 고속 쿼리 실행 : 최적화된 쿼리 엔진을 통한 빠른 데이터 처리 및 분석\n",
    "- 대규모 데이터 분석 : 구조화된 대용량 데이터에 대한 효율적인 분석 및 저장\n",
    "- 사용 편의성: SQL 기반 커리로 사용자 친화적.\n",
    "- 보안과 규제 준수: 데이터 보안 및 다양한 규제 준수 옵션 제공.\n",
    "\n",
    "4. 데이터 레이크\n",
    "- AWS Lake Formation  \n",
    "기능\n",
    "- 다양한 데이터 형식 지원 : 구조화 되지 않은 데이터에서부터 구조화된 데이터까지 다양한 형식의 데이터 저장 및 관리\n",
    "- 유연한 데이터 처리: 데이터 형식에 구애받지 않고 저장, 검색 및 분석 가능\n",
    "- 대규모 데이터 관리 : 데이터 레이크는 방대한 양의 데이터를 효과적으로 관리할 수 있는 능력을 가짐\n",
    "- 비용 효율성 : 사용한 만큼만 비용 지불, 다양한 저장 옵션 제공. \n",
    "- 데이터 통합: 다양한 소스의 데이터를 하나의 위치에서 관리하고 분석\n",
    "\n",
    "### Computing\n",
    "#### 클라우드 기반 Computing\n",
    "1. 예시: AWS EC2, Google Compute Engine\n",
    "2. 기능\n",
    "- 인스턴스 유형과 환경: 여러가지 인스턴스 유형을 제공하여, 메모리, 컴퓨팅, 스토리지 최적화 등 다양한 필요에 맞게 선택 가능.\n",
    "- 자동 스케일링: 트래픽이나 작업 부하에 다라 자동으로 리소스를 스케일링하여 효율성 및 비용 절감\n",
    "- 종합적인 보안: 네트워크 보안, 데이터 암호화, 접근관리 등을 포함한 종합적인 보안 솔루션 제공\n",
    "- 전역 네트워크: 전 세계 데이터 센터를 통해 글로벌 액세스 및 가용성 보장\n",
    "3. MLOps 활용 예\n",
    "- 대규모 딥러닝 모델을 위한 GPU인스턴스 사용, 전 세계 사용자를 대상으로 하는 서비스의 글로벌 배포 및 로드 밸런싱\n",
    "\n",
    "#### GPU/TPU\n",
    "1. 예시\n",
    "- NVIDIA의 Tesla 시리즈 GPU, Google Cloud TPU\n",
    "2. 기능\n",
    "- 딥러닝 최적화: 특히 딥러닝 작업을 위해 설계된 아키텍쳐로, 복잡한 신경망을 빠르게 트레이닝.\n",
    "- 고속 메모리 접근: 고속 메모리 및 대역폭으로 대량의 데이터를 신속하게 처리\n",
    "- 에너지 효율적 설계: 고성느을 제공하면서도 에너지 소비를 최소화하는 효율적 설계.\n",
    "- 확장가능한 인프라: 여러 GPU 또는TPU를 연결하여 대규모 병렬 처리 구성 가능\n",
    "3. MLOps 활용 예\n",
    "- 고해상도 이미지 인식, 복잡한 언어 모델 트레이닝, 대규모 데이터셋에서의 빠른 추론\n",
    "\n",
    "#### 서버리스 컴퓨팅\n",
    "1. 예시\n",
    "- AWS Lambda, Google Cloud Functions, Azure Functions\n",
    "2. 기능\n",
    "- 코드 중심 실행: 서버 구성이나 관리 없이 바로 코드 실행에 집중 가능\n",
    "- 다양한 트리거 옵션: HTTP 요청, 데이터베이스 이벤트, 큐 메시지 등 다양한 이벤트에 의해 트리거 되는 실행\n",
    "- 빠른 배포 및 업데이트: 새로운 코드 버전을 빠르게 배포하고 업데이트. \n",
    "- 통합 에코시스템: 클라우드 서비스와의 긴밀한 통합으로 복잡한 작업을 쉽게 구성\n",
    "3. MLOps 활용 예\n",
    "- 대규모 딥러닝 모델을 위한 GPU 인스턴스 사용, 전 세계 사용자를 대상으로 하는 서비스의 글로벌 배포 및 로드 밸런싱\n",
    "\n",
    "#### 컨테이너화 컴퓨팅\n",
    "1. 예시\n",
    "- Docker 컨테이너\n",
    "2. 기능\n",
    "- 개발 및 배포 일관성: 모든 개발, 테스트, 프로덕션 환경에서 동일한 소프트웨어 환경 보장\n",
    "- 자동 오케스트레이션: Kubernetes와 같은 도구를 사용하여 컨테이너 배포, 관리, 스케일링 자동화\n",
    "- 마이크로 서비스 아키텍쳐 지원: 각각의 컨테이너가 독립적인 서비스로 작동, 유연하고 확장 가능한 서비스 구축 지원\n",
    "- 리소스 효율성: 컨테이너는 가볍고 빠르며, 필요한 리소스만 사용하여 효율적인 운영 가능\n",
    "3. MLOps 활용 예\n",
    "- 다양한 머신러닝 모델을 컨테이너화하여 일관된 환경에서 트레이닝 및 추론, 모델의 쉬운 업데이트 및 롤백, 마이크로서비스 기반의 머신러닝 시스템 구축"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

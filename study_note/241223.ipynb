{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastcampus\n",
    "## 모델 평가의 구성요소\n",
    "1. 정성평가  \n",
    " 모델에 들어가는 입력값과 그에 따른 모델의 출력값을 사람이 직접 확인해 보면서, 모델의 성능을 평가  \n",
    "2. 정량평가  \n",
    " 모델의 성능이 얼마나 좋은지 수치로 나타내는 평가지표(Evaluation Metric)함수를 설정해두고, 해당 지표를 활용해 성능을 평가  \n",
    " - 정량평가 지표  \n",
    "   모델이 정답을 얼마나 맞혔는지를 수치로 나타내는 지표  \n",
    "   손실함수의 경우 모델의 학습과정에 직접 기여하지만, 정량평가는 그렇지 않다.  \n",
    "    - 손실함수는 배를 밀어주지만, 정량평가는 길을 알려주는 느낌으로 생각하면 된다.  \n",
    "   연구를 진행한다면 비교를 위해 완전히 동일한 평가지표를 사용해야 한다.  \n",
    "    MAE,MSE,RMSEm교차 엔트로피 등 수많은 함수들이 손실함수, 혹은 정량평가 지표로 사용된다.  \n",
    "\n",
    "## 모델의 복잡도\n",
    "모델이 더 복잡하고 어려운 데이터까지 학습할 수 있는 용량.  \n",
    "일반적으로 파라미터의 수가 많을수록 복잡도가 커진다.  \n",
    "복잡도가 과도하게 커질경우 과적합(overfitting)이 발생할 수 있다.  \n",
    "\n",
    "## 잘못된 데이터셋 분할의 결과\n",
    "### 데이터 누출\n",
    "학습 데이터셋 일부가 평가용 데이터셋에 포함되어, 모델 성능이 비정상적으로 높게 측정되는 문제  \n",
    "- 원본 데이터셋이 중복샘플이나 매우 유사한 샘플들을 많이 포함하는 경우 생기기 쉬움  \n",
    "\n",
    "### 평가용 dataset의 대표성 부족\n",
    "test set 이 너무 작거나, 구성이 너무 불균형해, 평가 결과의 신뢰도가 부족한 경우  \n",
    "- 분류 문제의 test set이 특정 클래스의 샘플을 하나도 포함하지 않을 경우  \n",
    "\n",
    "## data_set의 적절한 분할 방법\n",
    "### 2분할 방법\n",
    "전체 data_set을 2개로 분할해 traing과 validaiton으로 사용\n",
    "### 3분할 방법\n",
    "전체 data_set을 3개로 분할해 training, validation, test 3개로 나눔\n",
    "\n",
    "Validation data set 에서의 성능평가 결과는 모델의 구조를 결정하는 하이퍼 파라미터의 최적화와 학습완료된 모델의 선별에 사용된다.  \n",
    "\n",
    "### k-fold 교차 검증(cross validation)\n",
    "데이터셋을 k개의 같은 크기의 부분집합으로 나누고, 각 fold를 번갈아 가며 검증용 데이터로 사용해 모델을 학습/검증하는 과정을 반복, 총 k 번의 학습과 검증을 진행한 뒤, 각각의 결과를 평균내어 모델의 최종 성능을 추정하는 방식\n",
    "- 모든 데이터를 학습 및 검증에 사용하므로 효율적으로 학습데이터를 활용할 수 있고, 다양한 데이터를 검증에 활용해 편향을 줄일 수 있다.\n",
    "\n",
    "## 모델의 일반화 성능\n",
    "### 내삽(interpolation)\n",
    "학습데이터셋의 범위 내 에서 새로운 데이터를 예측하거나 분류하는 것.\n",
    "### 외삽(extrapolation)\n",
    "학습데이터셋의 범위를 넘어서는 새로운 데이터를 예측하거나 분류하는 것. 학습 데이터에 없는 영역에서의 패턴을 추정해야 하기 때문에 성능이 낮아지기 쉽다.\n",
    "\n",
    "### data_set의 구성\n",
    "validation data set은 내삽성능의 측정을 위해 학습용 데이터셋과 같은 분포를 유지한다.  \n",
    "test data set은 외삽성능의 측정도 가능하도록 최대한 다양한 샘플들을 포함해 구성한다.\n",
    "\n",
    "validation data set, test data set은 어느정도 샘플수가 확보된 이후로는 양을 늘리기보다는 품질을 관리하는 것이 더 중요하다.\n",
    "\n",
    "## 기초정량평가 방법론\n",
    "### 다양한 정량평가 지표\n",
    "#### 낯선 평가지표 아는척하기\n",
    "1. 최소화 지표와 최대화 지표\n",
    "- 작을수록 좋은 지표는 Minimizing Metric 클수록 좋은 지표는 Maximizing Metric 이라고 함\n",
    "2. 평가지표 값의 범위 확인\n",
    "- 평가지표가 가질 수 있는 값의 범위, 최소값이나 최대값이 정해져 있는가? (ex. 0~100%)\n",
    "\n",
    "#### 혼동 행렬 (Confusion Matrix)\n",
    "이진 분류 문제에서 모델의 예측치와 실제값에 따른 샘플수를 표 형태로 나타낸 것.  \n",
    "각 항목의 값은 예측이 맞았는지 틀렸는지를 나타내는 (True|False)와 결과가 양성인지 음성인지를 나타내는 (Positive|Negative)를 붙여 표시한다.\n",
    "- FP == False + Positive == 검사결과 양성이 나왔으며 실제로도 걸리지 않음\n",
    "\n",
    "1. 정밀도 = 모델이 양성으로 예측한 샘플중 정답의 비율 == TP / (TP + FP)\n",
    "2. 재현율 = 실제로 양성인 샘플 중 모델이 (양성으로)정확하게 분류된 샘플의 비율 == TP / (TP + FN)\n",
    "3. F1 스코어 = Recall과 Precision을 동시에 비교하기 위해 조화평군을 취한것\n",
    "4. ROC Curve = 음성/ 양성을 판단하는 기준값의 변화에 따라, 전체에서 TP,FP의 비율이 변호하는 추세를 나타낸 곡성\n",
    "5. AUC = ROC Curve의 아래쪽 영역의 넓이로 측정되며, 정밀도와 재현율을 모두 중요하게 고려하는 정량평가 지표\n",
    "\n",
    "#### 예측값과 목표값의 차이\n",
    "1. MAE(Mean Absolute Error) = 오차에 절대값을 취한 것의 평균\n",
    "2. MSE(Mean Squared Error) = 오차를 제곱한 것의 평균\n",
    "3. RMSE(Rood Mean Squared Error) = MSE의 제곱근으로, MSE를 사용하면 오차가 원래의 수치와 다른 단위로 표시된다는 점을 보완한다.\n",
    "\n",
    "#### 편집거리(Edit Distance)\n",
    "시계열 모델에서 주로 사용, 몇번의 삭제/추가(edit)을 거쳐야 출력값을 목표값으로 만들 수 있는가. = Minimizing Metric\n",
    "\n",
    "### 정량평가 지표의 선택\n",
    "적절한 정령평가 지표는 문제와 상황마다 다르다.\n",
    "어느쪽이든, 각 평가지표의 특성을 이해하는 것도 중요하며, 같은 이진 분류 문제라고 해도 일반적으로는 정확도를 사용해도 좋지만, 데이터 불균형 문제가 있는 경우, 정밀도, 재현율이나 F1 스코어 등을 추가로 사용하는 것이 좋다.  \n",
    "\n",
    "회귀 문제에서는 MAE를 오차가 0인지 아닌지에, MSE를 이상치의 존재여부를 검사하기 위해 사용한다.  \n",
    "\n",
    "### 여러 정량평가 지표 함께 활용하기\n",
    "최적화 지표 : 모델의 최종적인 성능에 연관되어, 모델의 선택에 가장 중요한 영향을 미치는 평가지표  \n",
    "충족 지표 : 정해둔 한계값만 충족시킨다면, 그 이후로는 최종 결정에 영향을 주지 않는 지표\n",
    "\n",
    "## 휴먼 베이스라인 & 목표 성능지교의 설정\n",
    "### 모델 성능의 비교\n",
    "#### Baseline Score\n",
    "높은 성능을 내기 위한 목적이 아니라 실험과정에서 비교용으로 사용하는 모델의 정수\n",
    "- 입력값을 무시하고 k개의 클래스 중 아무거나 고르는, 랜덤 베이스라인 모델의 정확도는 1/k*100%가 되어야 한다.  \n",
    "베이스라인 성능의 활용\n",
    "1. 평가지표 측정이 제대로 되고 있는지 검증\n",
    "2. 학습 과정상 에러가 있는지 확인\n",
    "\n",
    "다른 방식의 베이스라인\n",
    "- 나이브 베이즈 분류기\n",
    "- k-최근접이웃 분류\n",
    "- 다중 로지스틱 회귀\n",
    "\n",
    "#### 리더보드\n",
    "공개 데이터셋의 경우, 연구자들이 각자 학습한 모델의 성능을 공유하고 비교해보기 위한 순위표, 리더보드가 제공되는 경우가 있다.\n",
    "\n",
    "#### SOTA(State Of The Art)\n",
    "최첨단이라는 뜻으로 쓰이며, 리더보드에서는 1위를 달성한, 세계 최고 성능의 모델을 뜻하는 의미로 쓰인다.\n",
    "\n",
    "## 체계적인 정성평가 방법론\n",
    "### 정성평가와 정량평가의 상호보완성\n",
    "정량평가는 모델의 학습 및 선택을 효율적으로 진행할 수 있게 하고, 일부 과정을 자동화 하기에도 매우 편리한 방법이지만, 데이터셋 자체에 없거나 매우 희귀한 데이터에서 모델의 결과는 정량평가를 통해 드러나기 어렵다.\n",
    "\n",
    "### 정량평가로는 드러나지 않는 것들\n",
    "#### 모델의 이해할 수 없는 오답패턴\n",
    "모델이 학습과정에서 어떤 과정으로 정답을 도출하는지는 사람이 투명하게 알 수 없는 경우가 대부분  \n",
    "모델이 똑같은 틀린 답을 내놓더라도 실제로 어려운 난이도의 샘플을 틀리는 경우와, 알수 없는 이유로 쉬운 난이도의 샘플을 틀리는 경우로 나뉜다.  \n",
    "후자의 경우, 그대로 방치했을 때 서비스 이용자가 모델의 결과를 신뢰하기 어렵게 만들지만, 의외로 데이터 노이즈의 제거나 모델 구조 개선 등으로 전자보다 쉽게 개선할 수 있는 경우가 많아 주의 깊게 보아야 한다.\n",
    "\n",
    "#### 평가지표 자체의 빈틈\n",
    "데이터 모호성 등의 이유로, 평가지표 자체에서 특정 케이스에 대해 모델 출력값의 품질을 제대로 평가하기 어려운 경우\n",
    "- 이미지 생성모델의 사람 손 그림\n",
    "- OCR(광학문자인식; Optical Character Recognition) 문제의 띄어쓰기 이슈\n",
    "\n",
    "### 정성평가가 어려운 이유\n",
    "#### 확장성이 떨어지는 정성평가\n",
    "정성평가는 결국 사람이 직접 진행해야 되는 과정이며, 매우 지루하고 비슷한 일이 반복되는 작업인 경우가 많음.\n",
    "#### 주관성을 배제하기 힘든 정성평가\n",
    "정성평가는 사람의 판단기준으로 모델의 예측결과를 판단하는 것이므로 완전히 객관적으로 진행하기가 어렵다\n",
    "\n",
    "### 정성평가 팁\n",
    "#### 정성평가 과정에 대한 대략적인 분석\n",
    "풀려는 문제와 모델, 데이터에 대해 잘 알고 있는 한명, 또는 소수의 몇 명이 여러 방법으로 소규모 정성평가를 직접 진행해보며 분석한다.\n",
    "- 정성평가의 속도를 대략적으로 확인\n",
    "- 평가 과정에서 비효율적인 부분이 있는지, 이를 간단히 개선해볼 방법이 있는지 확인한다.\n",
    "#### 샘플 관찰 계획 세우기\n",
    "앞 단계에서 확인한 속도 정보를 기반으로 몇명이 참여해 몇시간 동안 몇개의 샘플을 확인할 것인지, 무리하지 않는 범위에서 계획을 세운다.\n",
    "- 모든 샘플ㅇ르 한번헤 하는 것 보다는 소규모로 진행 후 추가 진행을 판단한다.\n",
    "- 순서대로 데이터 처리 하지 말고 랜덤하게 샘플링 해서 해본다.\n",
    "#### 점진적인 정성평가 프로세스\n",
    "전체 틀린 케이스 중 상당수가 한가지 문제로 인해 발생하는 경우가 많기 때문\n",
    "#### 발견된 이슈의 기록 및 분류\n",
    "정성평가를 진행하며 발견된 문제를 최대한 구체적, 객관적으로 기록한다.\n",
    "- 사람이 봐도 어려운 샘플(x) / 빛 번짐이 심해 알아보기 힘든 샘플 (o)\n",
    "자주 등장하는 이슈들은 간결한 표현으로 카테고리화 하여 기록해둔다.  \n",
    "모델의 성능에 문제를 일으키는 인풋 데이터의 패턴을 트리거(trigger)라고 한다.\n",
    "- 트리거 샘플들을 모아 별도의 평가용 데이터솃을 구성하면\n",
    "\n",
    "## 모델 에러의 분석\n",
    "### 머신러닝 모델의 최적화\n",
    "#### 모델의 복잡도\n",
    "모델이 더 복잡하고 어려운 데이터까지 학습할 수 있는 용량, 모델의 용량(Capacity)라고 부르기도 함  \n",
    "(대체적으로 파라미터 수가 많을수록 구조가 복잡함)  \n",
    "(딥러닝의 경우 레이어 및 뉴런 수가 많을수록 복잡도가 커짐)\n",
    "\n",
    "#### 과적합(overfitting)\n",
    "모델이 학습데이터의 패턴에만 과하게 학습되어, 학습 데이터에서의 손실함수 값는 0에 수렴하지만 평가 데이터셋 등 새로운 데이터에 대해서는 전혀 성능을 내지 못하는 상황\n",
    "- 더 다양한, 고품질의 데이터가 필요함\n",
    "- 모델이 학습 데이터의 패턴을 전부 암기해버린 상황\n",
    "- 모델의 복잡도 > 학습 데이터의 복잡성 의 상태이기 때문에 발생\n",
    "- 큰 분산(Variance) 때문에 발생, 데이터에 너무 복잡한 가정을 사용한 모델\n",
    "#### 과소적합(Underfitting)\n",
    "과적합과는 반대로, 모델이 학습 데이터셋조차 전부 학습하지 못해 검증 및 평가 데이터셋은 물론 학습데이터셋에서도 최적화가 충분히 진행되지 못한 상태를 과소적합이라고 한다.\n",
    "- 큰 편향(Bias) 때문에 발생. 데이터에 대한 너무 단순한 가정을 사용한 모델\n",
    "\n",
    "### 과적합 문제의 해결방법\n",
    "#### L1,L2 Regularization\n",
    "과적합 문제의 해결방법으로, 모델 파라미터의 L1 또는 L2 norm을 손실함수값에 더해, 학습과정에서 자연스럽게 파라미터 자체의 크기가 줄어들고, 그에 따라 모델의 복잡도가 떨어지도록 유도하는 방식\n",
    "#### Augmentation\n",
    "정답 라벨이 바뀌지 않는 한도 내에서 input 데이터를 여러 방법으로 변형시켜 새로운 데이터로 활용하는 방식  \n",
    "데이터의 복잡성을 늘려 과적합 문제 해결\n",
    "- 이미지의 경우 좌우/상하 반전, 밝기 및 색상 조정 등\n",
    "- 정형 데이터의 경우 일부 변수의 값에 랜덤 노이즈값을 더하거나 값을 서로 교체 하는 등\n",
    "\n",
    "#### Early Stopping\n",
    "학습, 검증용 데이터 셋의 손실함수 값 차이가 커지기 시작하는 시점에, 학습을 일찍 종료하여, 과적합 문제가 생기는 것을 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 개인학습\n",
    "## 마크다운 문서 공부\n",
    "1. 그림 삽입 방법 == \"![그림 제목] (링크)\" 단 띄어쓰기 없이.\n",
    "![ai 고양이 그림](https://images.playground.com/9438e5e7ea8d42f8820459256ce159c7.jpeg)\n",
    "\n",
    "2. 내부에 코드 블록 넣기\n",
    "'''언어이름\n",
    "내용\n",
    "'''\n",
    "형식으로 작성해야 한다. 이때 주의해야 할 점은 ; 옆에 있는 홑따음표(') 가 아닌 1 왼편에 있는 Back tick(`)을 사용해야 한다는 것이다.\n",
    "============================\n",
    "\n",
    "```python\n",
    "print(\"Hello World\")\n",
    "```\n",
    "\n",
    "그 외의 문법은 크게 사용할 일이 없기 때문에 딱히 안 외워도 될 것 같다. 필요하면 그때 그때 찾아보는 걸로 ㅎㅎ\n",
    "\n",
    "## README.md 파일 작성법\n",
    ".md 라는 확장자는 Git에서만 사용하는 것이고 windows 혹은 Mac OS 에서는 .txt를 확장자로 사용한다.\n",
    "예상했던 대로, md는 MarkDown의 약자로 대부분의 문법을 공유하는 것 같다.\n",
    "하이퍼 링크는 <> 안에 링크 주소를 넣는 것이 일반적."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fastcampus",
   "language": "python",
   "name": "fastcampus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

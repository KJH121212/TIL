{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastcampus\n",
    "## CV Advanced\n",
    "### CV Backbone overview\n",
    "#### CNN의 등장 이유\n",
    "##### MLP(Multi Layer Perceptron)\n",
    "1. input -> hidden -> output으로 구성되어 있다.\n",
    "2. Input layer의 neuron 개수는 tabular data의 feature 수와 동일하다. = 각 feature가 neuron에 대응되기 때문\n",
    "3. MLP는 tabular data를 학습하는데 최적화 되어 있음  \n",
    "\n",
    "image data를 MLP의 input layer에 입력하기 위해서는 이미지를 flatten 해줘야 함.  \n",
    "-> image의 locality 특성을 모두 없애버림\n",
    "- Spatial locality(같은 물체라도 이미지마다 크기가 다름) \n",
    "- Positional inariance (같은 물체라도 다른 위치에 있을 수 있음)\n",
    "\n",
    "따라서 2d 형태의 image data를 분석하기 위해서 나온 것이 Convolution Filter 이다.  \n",
    "- 이미지를 flatten 하지 않고 연산 가능\n",
    "- Object의 구조와 주변 정보를 함께 연산할 수 있음\n",
    "- 같은 필터를 이미지 전체에 적용하여, 다른 위치에 똑같은 물체가 있는 경우 같은 연산을 수행\n",
    "\n",
    "##### CNN 이란?\n",
    "1. image의 locality 특성을 고려하여 학습할 수 있도록 설계된 neural network\n",
    "2. MLP 에서 hidde layer를 여러겹 쌓았던 것처럼, Convolutional layer를 여러겹 쌓아서 만든 deep neural networks\n",
    "3. CNN을 통해 MLP의 한계를 극복할 수 있음 = locality 특성 살릴 수 있음\n",
    "\n",
    "##### imageNet Large Scale Visual Recognition Challenge\n",
    "AlecNet이라는 CNN 기반 모델 도입 이후 이미지 분류 성능이 대폭 상승하였음  \n",
    "VGG 모델은 구조가 단순하지만 깊은 네트워크의 중요성을 알린 모델  \n",
    "ResNet 이후로는 사람보다 실수가 더 적은 것을 알 수 있음.\n",
    "- 네트워크를 깊게 쌓을 경우 생기는 무제점을 해결, 기존보다 더 깊은 네트워크 제안 (152 layer)  \n",
    "EfficintNet 기존 네트워크들이 가진 trade-off를 분속\n",
    "- 네트워크의 폭, 깊이, 해상도의 균형을 통해 효율적이고 정확한 네트워크를 제안\n",
    "\n",
    "##### CNN의 한계점\n",
    "1. image 안에서 멀리 떨어진 객체끼리 관련성을 파악하기 어려움\n",
    "2. image의 각 파트가 image 이해에서 얼마나 중욯나지, 얼마나 서로 관련이 있는지 평가할 수 없음.\n",
    "\n",
    "##### Transformer\n",
    "1. VIT & Swin\n",
    "- Transformer 구조를 computer vision에 적용하여 해결한 ViT(Vision Transformer) 등장\n",
    "- 더 나아가 CNN 특성을 ViT에 다시 적용한 Swin Transformer 등장\n",
    "\n",
    "#### Convolution filter\n",
    "##### Filter\n",
    "1. 이미지처리를 위해 사용되는 행렬\n",
    "- 주로 edge detection, blurring등을 위해 사용되었음\n",
    "- kernel, mask라고도 불림\n",
    "2. 같은 filter로 이미지 전체에 slidiing window로 convolution 연산 수행\n",
    "3. convolution 된 결과를 feature map 혹은 acitivation map이라고 함.\n",
    "- 고정된 filter 대신 우리가 원하는 방향으로 filter값을 학습하는 것이 CNN의 목적이다.\n",
    "##### Channel\n",
    "1. Grayscale image는 1개의 channel(흑백)을 가지지만, 일반적인 이미지(RGB)는 3개의 channel로 이루어져 있음\n",
    "2. Convoltuion filter를 적용할 때 Channel 수를 고려해야함.\n",
    "- 32*32*3 image에 5*5*3 filter를 적용한다고 했을 때, 한번의 연산에 5*5*3영역만큼 연산된다.\n",
    "- sliding window로 이미지 전체를 연산하면 32*32*1크기의 feature map을 얻는다.\n",
    "- 더 깊은 feature map을 얻고 싶다면, 더 많은 convoltuino filter를 사용하면 된다.\n",
    "##### Feature Map\n",
    "Convolution 연산이 수행될 수록 작아짐. 동일한 크기/ 원하는 크기의 feature map 만들 수 없음\n",
    "1. Stride : sliding window에서 한 step의 거리를 조절 (feature Map 크기를 조잘 할 수 있음) \n",
    "2. Padding : image 주변에 값 0의 빈칸을 추가 (zero-padding)\n",
    "3. Pooling : Parameter를 사용하지 않고 feature map의 크기 축소\n",
    "\n",
    "#### CNN\n",
    "##### CNN\n",
    "1. AlexNet = CNN을 사용한 최초의 모델\n",
    "- ReLU 활성함수 사용\n",
    "- Dropout을 통해 overfitting 방지\n",
    "2. VGG = 깊은 네트워크를 활용\n",
    "- AlexNet은 11*11,5*5,3*3 filter를 사용한데 비해 VGG는 3*3filter만 사용함.\n",
    "- 3*3filter를 여러개 쌓으면 receptive field size가 커짐 = (parmeter 개수에서 이득을 볼 수 있음 )\n",
    "\n",
    "##### ResNet\n",
    "CNN는 네트워크가 깊을 수록 좋지만 실제로는 gradient의 vanishing promblem이 발생한다.  \n",
    "해당 문제를 해결하기 위해 identity shortcut을 이용했다.  \n",
    "Residual block(skep connenction)\n",
    "- 각 block의 input을 convolution연산에 더한 값을 output으로 사용  \n",
    "이를 통해 backpropagation을 진행할 때 vanishing gradient를 막을 수 있음.\n",
    "\n",
    "##### EfficientNet\n",
    "ResNet 이후 오차는 낮지만 동시에 시간이 너무 오래 걸리는 문제점이 발생\n",
    "- 성능은 좋지만, 속도가 빠르고 크기가 작은 모델에 대한 요구가 증가\n",
    "    - 모델 크기를 scale up 하는 과정에 비효율이 있었나? 라는 의문에서 시작됨\n",
    "\n",
    "1. width scaling\n",
    "- Channel 사이즈를 키움\n",
    "- 이미지의 미세한 특징을 잘 잡음\n",
    "2. depth scaling\n",
    "- 네트워크를 깊게 쌓으며 High level feature를 이해하는데 도움이 됨\n",
    "- gradient vanishig 의 위험성 \n",
    "3. resolution scaling \n",
    "- 이미지가 고화질인 경우 미세한 특징을 잘 잡아냄  \n",
    "- image size가 커짐에 따라 연산량 증가 (증가되는 연산량에 비해 accuracy가 많이 향상 되지 않음)\n",
    "\n",
    "4. compound scaling\n",
    "위의 3가지 scaling을 시작  \n",
    "Depth, width, resolution의 균형 파악 하는 것이 중요  \n",
    "- compound scaling method 제안\n",
    "\n",
    "### Transformer 이해하기\n",
    "#### Transformer의 연구\n",
    "최근 CV domain에서도 transformer backbone이 주류가 됨  \n",
    "NLP에서 발생하는 문제점을 해결하기 위해 고안됨\n",
    "1. sequence data를 처리할 때 순차적으로 처리함. = 데이터 길이가 길어지면 정보손실이 발생함.(앞부분의 x가 h에 미치는 영향이 작아짐)\n",
    "2. Attention: next token을 예측할 때, sequence 내의 다른 위치에 있는 정보들과의 상관 관계가 중요함. 이를 고려해야함  \n",
    "2개의 문제점 때문에 transformer가 연구됨\n",
    "CNN에서도 동일한 문제 발생  \n",
    "\n",
    "#### Transformer의 구조\n",
    "input data -> tokenization -> Embedding -> Positional encoding -> transformer block -> output\n",
    "1. Tokenization\n",
    "문장을 토큰 단위로 분할\n",
    "- 단어, 구두점 등 '의미 있는 단위'를 나타냄. (\"playing\" -> \"play\", \"-ing\" 같은 형태로 나눔)\n",
    "- 문장의 시작이나 끝을 나타내는 token도 추가\n",
    "- 각 token에 사전에 정의된 단어번호 할당\n",
    "2. Embedding\n",
    "Token을 embedding으로 변환 (학습 가능한 값으로 변환)\n",
    "3. Positional encoding\n",
    "단어의 위치가 의미가 있음. (위치정보를 word embedding에 더하여 위치정보를 추가)  \n",
    "최근에는 Positional Embedding을 통해 위치정보 역시 학습 가능한 파라미터로 두는 경우가 많아짐.\n",
    "\n",
    "위의 3가지 root를 다 거치면 최종적인 input이 결정된다.\n",
    "\n",
    "#### Attention score\n",
    "query, key, value 3가지로 mapping하고 나온 key와 query의 행렬 곱을 통해 attention score를 계산함\n",
    "- 서로 얼마나 관계가 있는지를 확인\n",
    "거기에 value를 곱해 key가 가진 정보를 통합한다.\n",
    "\n",
    "### swin Transformer\n",
    "patch를 더 효율적으로 설계 할 수 있는 transformer 구조  \n",
    "inductive bias 고려하여 모델 구조를 설계 = CNN의 구조적 이점 반영  \n",
    "1. Hierarchical 구조 : 작은 단위의 patch 부터 시작해서 점점 merge 해가는 방식\n",
    "2. 계층적 구조로 각 단계 마다 다른 representation을 가지기 때문에 다양한 크기의 객체를 다뤄야 하는 태스크에 유리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# project에 대한 상객\n",
    "## sinogram을 이용할 경우 이점\n",
    "회전을 시킬 필요가 없지 않을까?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

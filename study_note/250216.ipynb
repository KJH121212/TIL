{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastcampus\n",
    "## CV Advanced\n",
    "### CV Backbone overview\n",
    "#### CNN의 등장 이유\n",
    "##### MLP(Multi Layer Perceptron)\n",
    "1. input -> hidden -> output으로 구성되어 있다.\n",
    "2. Input layer의 neuron 개수는 tabular data의 feature 수와 동일하다. = 각 feature가 neuron에 대응되기 때문\n",
    "3. MLP는 tabular data를 학습하는데 최적화 되어 있음  \n",
    "\n",
    "image data를 MLP의 input layer에 입력하기 위해서는 이미지를 flatten 해줘야 함.  \n",
    "-> image의 locality 특성을 모두 없애버림\n",
    "- Spatial locality(같은 물체라도 이미지마다 크기가 다름) \n",
    "- Positional inariance (같은 물체라도 다른 위치에 있을 수 있음)\n",
    "\n",
    "따라서 2d 형태의 image data를 분석하기 위해서 나온 것이 Convolution Filter 이다.  \n",
    "- 이미지를 flatten 하지 않고 연산 가능\n",
    "- Object의 구조와 주변 정보를 함께 연산할 수 있음\n",
    "- 같은 필터를 이미지 전체에 적용하여, 다른 위치에 똑같은 물체가 있는 경우 같은 연산을 수행\n",
    "\n",
    "##### CNN 이란?\n",
    "1. image의 locality 특성을 고려하여 학습할 수 있도록 설계된 neural network\n",
    "2. MLP 에서 hidde layer를 여러겹 쌓았던 것처럼, Convolutional layer를 여러겹 쌓아서 만든 deep neural networks\n",
    "3. CNN을 통해 MLP의 한계를 극복할 수 있음 = locality 특성 살릴 수 있음\n",
    "\n",
    "##### imageNet Large Scale Visual Recognition Challenge\n",
    "AlecNet이라는 CNN 기반 모델 도입 이후 이미지 분류 성능이 대폭 상승하였음  \n",
    "VGG 모델은 구조가 단순하지만 깊은 네트워크의 중요성을 알린 모델  \n",
    "ResNet 이후로는 사람보다 실수가 더 적은 것을 알 수 있음.\n",
    "- 네트워크를 깊게 쌓을 경우 생기는 무제점을 해결, 기존보다 더 깊은 네트워크 제안 (152 layer)  \n",
    "EfficintNet 기존 네트워크들이 가진 trade-off를 분속\n",
    "- 네트워크의 폭, 깊이, 해상도의 균형을 통해 효율적이고 정확한 네트워크를 제안\n",
    "\n",
    "##### CNN의 한계점\n",
    "1. image 안에서 멀리 떨어진 객체끼리 관련성을 파악하기 어려움\n",
    "2. image의 각 파트가 image 이해에서 얼마나 중욯나지, 얼마나 서로 관련이 있는지 평가할 수 없음.\n",
    "\n",
    "##### Transformer\n",
    "1. VIT & Swin\n",
    "- Transformer 구조를 computer vision에 적용하여 해결한 ViT(Vision Transformer) 등장\n",
    "- 더 나아가 CNN 특성을 ViT에 다시 적용한 Swin Transformer 등장\n",
    "\n",
    "#### Convolution filter\n",
    "##### Filter\n",
    "1. 이미지처리를 위해 사용되는 행렬\n",
    "- 주로 edge detection, blurring등을 위해 사용되었음\n",
    "- kernel, mask라고도 불림\n",
    "2. 같은 filter로 이미지 전체에 slidiing window로 convolution 연산 수행\n",
    "3. convolution 된 결과를 feature map 혹은 acitivation map이라고 함.\n",
    "- 고정된 filter 대신 우리가 원하는 방향으로 filter값을 학습하는 것이 CNN의 목적이다.\n",
    "##### Channel\n",
    "1. Grayscale image는 1개의 channel(흑백)을 가지지만, 일반적인 이미지(RGB)는 3개의 channel로 이루어져 있음\n",
    "2. Convoltuion filter를 적용할 때 Channel 수를 고려해야함.\n",
    "- 32*32*3 image에 5*5*3 filter를 적용한다고 했을 때, 한번의 연산에 5*5*3영역만큼 연산된다.\n",
    "- sliding window로 이미지 전체를 연산하면 32*32*1크기의 feature map을 얻는다.\n",
    "- 더 깊은 feature map을 얻고 싶다면, 더 많은 convoltuino filter를 사용하면 된다.\n",
    "##### Feature Map\n",
    "Convolution 연산이 수행될 수록 작아짐. 동일한 크기/ 원하는 크기의 feature map 만들 수 없음\n",
    "1. Stride : sliding window에서 한 step의 거리를 조절  \n",
    "2. Padding : image 주변에 값 0의 빈칸을 추가 (zero-padding)\n",
    "3. Pooling : Parameter를 사용하지 않고 feature map의 크기 축소\n",
    "\n",
    "#### CNN\n",
    "##### CNN\n",
    "1. AlexNet = CNN을 사용한 최초의 모델\n",
    "- ReLU 활성함수 사용\n",
    "- Dropout을 통해 overfitting 방지\n",
    "2. VGG = 깊은 네트워크를 활용\n",
    "- AlexNet은 11*11,5*5,3*3 filter를 사용한데 비해 VGG는 3*3filter만 사용함.\n",
    "- 3*3filter를 여러개 쌓으면 receptive field size가 커짐 = (parmeter 개수에서 이득을 볼 수 있음 )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

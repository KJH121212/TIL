{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "223e81f9-e084-421e-8830-151865c79b7c",
   "metadata": {},
   "source": [
    "# 개인 학습\n",
    "## 시간 복잡도\n",
    "시간복잡도란? 입력값과 연산 수행 시간의 상관관계를 나타내는 척도  \n",
    "\n",
    "O(1) - 상수 시간: 문제를 해결하는데 오직 한단계만 처리함.  \n",
    "O(log n) - 로그 시간: 문제를 해결하는데 필요한 단계들이 연산마다 특정 요인에 의해 줄어듬.  \n",
    "O(n) - 직선적 시간: 문제를 해결하기 위한 단계의 수와 입력값 n 이 1:1 관계를 가짐.  \n",
    "O(n log n) - 선형로그형: 문제를 해결하기 위한 단계의 수가 N*(log2N)번만큼의 수행시간을 가진다.  \n",
    "O(n^2) - 2차 시간: 문제를 해결하기 위한 단계의 수는 입력값 n의 제곱\n",
    "\n",
    "이걸 코드를 보고 복잡도를 계산한다? 미친짓임.  \n",
    "그냥 한번 돌려보고 시간 초과 나면 list를 dict로 바꾼 다던지 하는 식으로 우회법을 찾아야 겠다고 생각함.  \n",
    "처음 푼 방식은 list 내에 사람을 전부 뒤지는 거였지만 dict로 바꾼 후에는 index를 찾는데 걸리는 시간이 줄어들었음  \n",
    "그리고, 순위 변화를 list 업데이트가 아닌 dict 업데이트로 변경하니 소모 시간이 급격히 줄어듦."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e4b61e-27eb-46fe-ab58-828550870fb9",
   "metadata": {},
   "source": [
    "# Fastcampus\n",
    "## 비지도 학습이란? 비지도 학습이 필요한 이유\n",
    "비지도 학습 = Supervision, 즉 학습용 라벨(Y_train)을 활용하지 않고 입력데이터(x)로만 모델을 학습하는 방법론\n",
    "- 평가용 라벨(Y_label)은 활용할 수도 있고, 안할 수도 있음. 개발자 자유.\n",
    "- 입력 데이터 사이의 유사상, 관계를 활용\n",
    "- 행렬분해 등 별도 방법으로 데이터 행렬의 구조 분석\n",
    "- 입력값에 내재된 정보로 가상의 라벨을 생성\n",
    "- 자기 자신을 라벨로 활용\n",
    "\n",
    "## 군집화(clustering)\n",
    "데이터로부터 패턴을 파악해 데이터를 여러개의 군집으로 나누는 것.  \n",
    "서로 비슷한 데이터는 같은 그룹으로, 서로 다른 데이터는 다른 데이터로 묶어 주는 것\n",
    "### 분류(classification)와의 비교\n",
    "1. 분류문제 : 모델의 출력값과 레입블을 비교해 모델이 점점 레이블에 가까운 출력을 내놓도록 학습 시킴\n",
    "2. 군집화 문제 : 데이터들의 유사성을 기반으로 분리. 주어진 샘플들을 어떻게 나누어야 가장 유사한 샘플끼리 묶이게 될지, 데이터간 관계를 비교해 학습\n",
    "\n",
    "## 비지도 학습의 필요성\n",
    "모델을 학습시키기 위해서는 좋은 품질의 많은 양의 데이터가 필요함.  \n",
    "데이터 라벨링 작업은 상당한 비용과 시간을 필요로 함. 비지도 학습은 이 작업이 필요 없으므로 많은 데이터를 쉽게 구할 수 있음.\n",
    "- 그렇다고 비지도 학습은 데이터 라벨링에 드는 비용을 줄이기 위해 연구하는 것은 아님. (해결하려는 문제에서 차이가 나는 것)\n",
    "\n",
    "### Manifold Hypothesis\n",
    "일반적인 고차원 데이터들은 가능한 모든 데이터의 공간에 완전히 고르게 분포하는 것이 아니라, 상대적으로 매우 적은 차원의 매니폴드 구조를 이루고 있을 것이다.\n",
    "- Manifold?\n",
    "  1. 3차원 공가넹 흩뿌려진 탁구공\n",
    "  2. 2차원의 얇은 천 위에 찍혀 있는 점들\n",
    "  3. 2의 천이 3차원 공간상에서 휘어져 있다면? : 3차원 좌표로 위치 표현은 물론 가능하겠지만 천의 모양을 안다면 2차원만으로도 가능\n",
    "- 차원을 줄일 수 있다는 사실에 집중\n",
    "  1. 차원축소(Dimensionality Reduction)  \n",
    "    고차원 데이터의 정보를 최대한 보존하면서 훨씬 적은 차원으로 표현할 수 있는 방법을 찾는것 (PCA; 주성분 분석)\n",
    "  2. 노이즈 제거(Denoising)  \n",
    "    차원축소를 하면 정보가 유실된다는 사실을 역으로 활용해 원본데이터의 노이즈를 제거할 수 있다.\n",
    "  3. 시각화(Visualization)\n",
    "\n",
    "### 비지도 학습의 활용\n",
    "  1. 이상값 탐지(Anomaly Detection)  \n",
    "    일반적인 인풋값과 전혀 다른, 이상값을 찾아내는 문제 (ex. 불량품 찾기)\n",
    "  2. Word to Vector  \n",
    "    자연어 처리에서 사용하는 방법론으로 영어나 한국어 같은 자연어 단어들을 의미적인 연산이 가능하나임베딩 공간에 맵핑시킬 수 있음.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4661b699-1344-4ebd-9540-498edd118109",
   "metadata": {},
   "source": [
    "## 고차원 데이터의 이해\n",
    "데이터를 표현하는데 필요한 차원이 부족할 경우, 제대로된 분석이 힘들 수 있다.\n",
    "\n",
    "## 고차원에서 생기는 문제점들\n",
    "1. 컴퓨터 자원의 사용량\n",
    "    데이터의 차원 수가 커질수록 더 많은 정보를 학습하기 위해 모델도 더 커지는데, 그러면 연산량, 메모리 사용량 등이 같이 증가하고,  \n",
    "    결과를 보기 위해 더 오래 기다리거나 더 좋은 장비, 더 많은 비용이 필요하게 된다.\n",
    "2. 차원에 따른 데이터의 Sparsity 문제\n",
    "    고차원 데이터에서는 데이터 간의 거리가 지수적으로 증가하여, 공간 내 데이터의 밀도가 낮아져 모델 학습이 어려워진다.\n",
    "3. 직관적으로 이해하기 힘든 고차원 공간\n",
    "    - 정규분포: 100차원 벡터를 5000개모아 놓았을 때 가장 몰려 있는 곳은 어디인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476419c-656d-4c71-8e14-04101a036a7c",
   "metadata": {},
   "source": [
    "## SVD\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fastcampus",
   "language": "python",
   "name": "fastcampus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

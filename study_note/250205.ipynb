{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastcampus\n",
    "## 대회 개요\n",
    "CV 모델 학습부터 평가까지의 프로세스에 대한 경험을 목표로 함.  \n",
    "### 데이터\n",
    "1. 계좌번호, 저동차 번호판, 자동차 계기판, 진료비 영수증, 여권, 운전면허증, 주민등록증, 자동차 등록증 등의 17종의 문서 타입. \n",
    "    - train data  \n",
    "        1570장의 image (Class 별로 약 40~100개의 이미지)  \n",
    "        - 불균형 문제에 대해 생각해 봐야 할 것 같음.\n",
    "    - test data  \n",
    "        약 3140장의 image (Class 동일)\n",
    "        - train data보다 양이 많음. 이건 어떤 변수를 줄까?  \n",
    "        여러 augmentations가 적용되어 있음\n",
    "        - 많은 noise를 넣어 놓았기 때문에 이를 해결할 방법이 필요함.\n",
    "        - EDA를 통해 augmentation 종류를 파악하고 이를 대처할 수 있는 방식을 고안해야함. (회전)\n",
    "\n",
    "2. 모델\n",
    "3. 학습, 추론, 평가  \n",
    "    평가: Confusion Matrix를 통해 평가  \n",
    "    각 calss에 대한 f1 score를 개별적으로 계산 후 평균\n",
    "### EDA 팁\n",
    "학습이미지를 시각화 해서 인사이트 얻기. (특히 Test image를 확인해보고 noise 종류 정형화 후, 수정 방안 찾기)  \n",
    "Test image 가 rotate 된 경우가 많음. 이를 해결할 수 있는 방법이 뭐가 있을까?  \n",
    "- train image를 30도씩 돌린 이미지를 새로 만들어서 train data에 추가하는 방식이 가장 나을 것 같음.(sinogram 이용 가능? 의미 없나?)  \n",
    "\n",
    "image size를 통일 시켜야 함. resize를 어떠한 형식으로 하는것이 맞을까?  \n",
    "Label 분포를 보니 상대적으로 imbalacne 하면 StratifiedKFold를 사용하는 것이 좋지 않을까?\n",
    "\n",
    "### Weights & Biases\n",
    "ML 실험을 관리하고, 시각화하며, 공유하는데 도움이 되는 도구\n",
    "- Features\n",
    "    - 실험관리: 모델 학습 중에 생성되는 파라미터, metrics, logs를 자동 기록\n",
    "    - 대시보드: 실험 결과를 시각화하는 대시보드\n",
    "    - 협업 플랫폼: 팀원들과 실험을 공유하고, 함께 작업 가능\n",
    "    - 통합성: Tensorflow, Pytorch, HuggingFace등 다양한 프레임 워크와 라이브러리 지원\n",
    "\n",
    "### Augraphy library\n",
    "- 문서이미지를 ink, paper로 분리후 augmentation 처리함.\n",
    "\n",
    "### Ensemble\n",
    "1. 모델 및 데이터 기반 앙상블\n",
    "2. 학습 방법 기반 앙상블\n",
    "3. 예측 결과 기반 앙상블\n",
    "\n",
    "- 다양한 모델\n",
    "- 다양한 image size\n",
    "- augmentation\n",
    "- Seed 앙상블\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastcampus 학습\n",
    "1. 경사하강법 (GD)의 한계  \n",
    "local minimum에 빠질 수 있음\n",
    "- 파라미터 초기화를 잘하면 빠지지 않음.\n",
    "- 적절한 Learning Step을 잡는다.\n",
    "손실값 계산할때 큰 데이터에서 조금만 뽑아서 평균내어 구하는 것이 방법이다.\n",
    "\n",
    "##### Backpropagation 관점에서의 손실함수 해석\n",
    "vanishing gradient problem: 레이어의 수가 증가할수록 활성화 함수의 미분값이 계속해서 곱해져, 가중치에 따른 미분값이 0에 수렴하게 되는 문제.  \n",
    "MSE를 사용할 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

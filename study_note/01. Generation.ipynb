{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastcampus\n",
    "## 생성모델의 개요\n",
    "### 생성모델(Generative models)\n",
    "데이터는 저차원의 필수적인 정보로부터 생성 가능하다는 가정 하에 분포를 학습하여, 새로운 데이터를 생성하는 모델  \n",
    "- 데이터는 저차원의 필수적인 정보로 부터 생성 가능하다? = 하나의 image는 수많은 요소로 이루어져 있다.(ex. 어른+안경+남성+미소+...)  \n",
    "\n",
    "### 확률 분포 추정과 근사\n",
    "1. 가우시안 혼합 모델 = 정규분포\n",
    "- 여러 가우시안 분포를 활용해서 실제 데이터와 비슷하게 맞추는 방식\n",
    "2. 제한된 볼츠만 머신 = 볼츠만 분포\n",
    "- 인공신경망 기능의 생성모델\n",
    "- 에너지가 낮을 수록 확률밀도 함수가 커짐.\n",
    "- 목적함수를 정의하고 최적화 하는 방식\n",
    "3. 심층 신뢰망(DBN) = 여러 층의 RBM\n",
    "- 제한된 볼츠만 머신을 쌓은 듯한 모양을 하고 있음. 출력을 입력으로 다시 받는 형식\n",
    "4. 자기회귀(NADE) = 자기 회귀 기반의 생성모델\n",
    "- 현재의 픽셀값을 이전의 픽셀값에 의거 \n",
    "\n",
    "### 2014년 이후 딥러닝 기반의 생성모델\n",
    "1. 변분 오토 인코더 (VAE)\n",
    "- 흐린 영상 생성의 문제점 = AAE/LVAE로 발전 (분포 개선, 계층 모형) -> WAE, Beta-VAE, VQ-VAE 등으로 다시 발전(학습 개선, 벡터 양자화화)\n",
    "- 2019년 이후에는 VQ-VAE-2 (고성능, 고해상도 모델 제안), NVAE(Deep VAE) 가 나오면서 점점 발전하기 시작했다.\n",
    "2. 적대적 생성 신경망(GANs)\n",
    "- GANs, sGAN 발표 -> Deep Convolution GAN(DCGAN) -> 손실함수, 학습방법 연구 (LSGAN, WGAN)\n",
    "3. PixelR/CNN\n",
    "4. Normaliziing Flow\n",
    "5. 확산 모델(Diffusion Model) \n",
    "- 열확산 현상 이론 도입\n",
    "- 매우 느린 생성 속도가 단점이었지만 이를 해결할 수 있는 생성 방식 및 모델 개선을 통해 해결했다.\n",
    "- 여려 형태의 입력(TEXT, IMAGE, ...)를 받아 IMAGE를 생성할 수 있었다.\n",
    "- 높은 생성물 의미론 제어 방법 및 개인화 방법등장\n",
    "\n",
    "### 판별모델\n",
    "데이터 X가 주어졌을 때, 특성 Y가 나타날 조건부 확률을 직접적으로 반환하는 모델  \n",
    "= 주어진 데이터를 통해 데이터 사이의 경계를 예측  \n",
    "#### 판별 모델의 활용\n",
    "1. 어떤 데이터를 서로 다른 클래스로 분류해 주는 문제에 할용할 수 있음\n",
    "2. 정상 데이터에 대한 경께를 최대한 좁혀 이를 벗어나는 이상치를 감지하는 문제에도 응용이 가능 = 공장 불량품 찾기\n",
    "#### 로지스틱 회귀분석\n",
    "두 그룹의 경계를 곡선으로 FITTING 하기 위해 사용\n",
    "### 생성모델 \n",
    "데이터 X와 특성 Y의 결합 분포/ Y가 주어질 때 X의 조건부 분포를 추정하는 모델  \n",
    "주어진 Y가 없는 경우, 데이터 주변(marginal)분포를  추정하는 모델\n",
    "\n",
    "주어진 데이터를 통해 데이터 분포를 학습함\n",
    "#### 생성 모델의 어려움\n",
    "1. 고차원 데이터를 모델링\n",
    "- 복잡한 모든 특성의 분포를 알아야함. (데이터는 저차원의 정보로 표현 할 수 있다는 가정을 활용함)\n",
    "2. 평가 지표\n",
    "- 판별 모델과 달리 생성된 데이터에 대한 정량적 평가가 어려움 (ex. 더 나은 결과물이 무엇인지 평가할 지표가 애매함)\n",
    "\n",
    "#### 생성모델의 활용\n",
    "1. 이미지의 품질 개선\n",
    "2. 맥락에 맞게 이미지 빈 공간 자동 완성\n",
    "3. 오래된 사진 복구 / 새로운 색감 부여\n",
    "4. ai 음악 생성\n",
    "\n",
    "### 생성 모델과 최대 가능도 추정\n",
    "#### 가능도(likelihood)\n",
    "모델 파라미터에 의존하는 분포를 따르는 n개의 데이터를 관찰 한 후, 데이터로부터 모델 파라미터를 추정하는 방법 = 가능도를 최대화 하는 파라미터 찾기  \n",
    "log-likelihood를 사용하는 이유 = 곱셈이 덧셈 형태로 바뀌고, 미분이 쉬워지기 때문 (수식적 해석이 쉬워짐)\n",
    "#### 최대 가능도 추정법(MLE:Maximum Likelihood Estimation)\n",
    "가능도를 치대화 하는 파라미터를 찾는 방법  \n",
    "일반적으로 가능도 함수의 미분을 통해 계산\n",
    "### 생성 모델의 학습\n",
    "1. 데이터 분포를 어떻게 모델링 할까? = 모델을 어떻게 학습시켜야 하는가?\n",
    "- 데이터의 분포와 모델을 가깝게 해야함.\n",
    "2. 쿨백-라이블러 발산(Kullback-Leibler Divergence, KL-divergence) 최소화\n",
    "- 직관적으로 분포간 차이/거리 라고 이해하면 쉬움. 하지만 정확한 건 아님\n",
    "3. 하지만 우리는 데이터의 분포를 모르고 관측치 만 관측할 수 있음.\n",
    "\n",
    "## 생성모델의 평가지표\n",
    "### 판별모델의 평가지표\n",
    "1. 판별 모델은 정답(Ground Truth,GT)이 존재하므로 모델의 출력을 정답과 비교하기 용이하다.\n",
    "2. 범주형 데이터를 사용하는 경우(분류형)와 연속형 데이터(회귀 분석)를 사용하는 경우로 나눌 수 있다.\n",
    "- 범주형 데이터의 경우, 정확도/F-Score/ Recall 등의 여러 평가 지표가 존재하며 사용된다. \n",
    "- 연속형 데이터의 경우, MSE/MAE / R-squared/ 상관계수 등의 여러 평가지표가 존재하며 사용된다.\n",
    "### 생성모델의 평가가 어려운 이유\n",
    "1. 비교할 정답이 존재하지 않아 결과를 직접적으로 비교할 대상이 없음\n",
    "2. 훈련데이터를 정답으로 사용할 경우, 훈련 데이터를 그대로 복제하는 현상이 발생함 (ㄹㅇ 이걸 어캐 한거지?)\n",
    "3. 주관이 개입 될 여지가 있음 (같은 그림이지만 웃는건지 우는 것인지를 착각할 수 있음)\n",
    "### 생성모델의 평가지표\n",
    "#### 어떤 항목들을 평가해야 하는가?\n",
    "1. 충실도 : 이미지의 품질\n",
    "2. 다양성 : 이미지의 다양성\n",
    "#### 평가지표 종류\n",
    "1. IS(Inception Score)\n",
    "- Inception v3 모델을 분류기로 이용하여 GAN을 평가하기 위해 고안된 지표\n",
    "- 예리함과 다양성 두 가지를 주요하게 고려 (IS = Sharpness * Diversity)\n",
    "- 무질서도(Entropy) : 높을경우 -> 임의의 변수에 대해 예측되는 값이 많음 = 예측이 어려움\n",
    "- 예리함(Sharpness) : Entropy가 낮을수록 예리해짐\n",
    "- 다양성(Divergence) : 다양한 유형의 데이터가 분포\n",
    "- 한계: \n",
    "    1. 분류기 모델의 훈련 데이터 셋과 다른 데이터를 생성하는 경우 제대로 평가하기 어려움\n",
    "    2. 계속 같은 데이터를 생성(Mode Collapse), 기울기 기반(Gradient Based) 공격, 리플레이(Replay) 공격을 통해 점수 조작이 가능\n",
    "2. FID(Frechet Inception Distanch)\n",
    "- 낮을 수록 좋음\n",
    "- 생성된 데이터의 특징 벡터를 이용하여 훈련 데이터와의 거리를 계산\n",
    "- 한계\n",
    "    1. Fidelity와 Diversity를 각각 평가할 수 없음. = 어느쪽이 강조되었는지 혹은 균형 잡힌 모델인지 알 수 없음 \n",
    "3. 개선된 정밀도, 재현율 (Improved Precision & Recoall)\n",
    "- 정밀도(Precision) : Positive 예측한 것 중 실제로 Positive인 경우 = TP/(TP+FP)\n",
    "- 재현율(Recall) : 실제 positive 한 것 들 중에서 옳바르게 예측한 경우 = TP/(TP+FN) \n",
    "- 한계: 이상치에 민감, 실제 데이터와 생성된 데이터의 분포가 동일하더라도 샘플링에 따라 점수가 낮을 수 있음\n",
    "\n",
    "4. 조건부 정확도 (Conditional Accuracy) \n",
    "- 레이블이 주어졌을 때, 데이터의 분포를 학습 = 특저조건을 만족하는데이터를 생성 가능\n",
    "5. LPIPS(Learned Perceptual Image Patch Similarity) \n",
    "- 모델 특징 비교를 통한 영상간 유사도 측정 = 우리가 어떻게 두 이미지가 비슷하다고 느끼는가\n",
    "- 원본 영상과 유사도가 낮다 = 더 다양하게 생성했다로 해석\n",
    "6. CLIP-Score \n",
    "- Text-image 관계를 학습한 CLIP을 특징 추출기로 활용해서 유사도를 측정함함\n",
    "## 오토 인코더와 변분 오토 인코더\n",
    "### 오토인코더\n",
    "입력 데이터의 패턴을 학습하여 데이터를 재건하는 모델(비선형 차원 축소기법으로 활용 가능)\n",
    "1. 인코더: 데이터를 저차원 잠재 표현으로 요약\n",
    "2. 디코더: 저차원 잠재 표현으로 부터 데이터를 재구성\n",
    "3. 손실 함수 : 잠재 표현으로부터 복구한 데이터와 입력 데이터의 MSE\n",
    "### 디노이징 오토 인코더\n",
    "입력 데이터에 random noise를 주입하거나 Dropout layer를 적용  \n",
    "노이즈가 없는 원래 데이터로 재구성\n",
    "#### 원리\n",
    "안개 속에서 멀리 있는 물체를 구별할 때, 데이터의 특성들을 더욱 정확히 학습함(가려져도 구별되는 특별한 특징을 학습함)  \n",
    "노이즈에 강건한 잠재 표현 (미세하게 변형된 데이터도 같은 잠재 벡터로 표현 되도록)\n",
    "\n",
    "### 오토 인코더 활용\n",
    "학습한 오토 인코더의 인코더 부분을 특징 추출기로 활용  \n",
    "잠재 벡터로부터 분류, 클러스터링 문제 해결  \n",
    "  \n",
    "\n",
    "## 적대적 생성 신경망\n",
    "## 확산 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
